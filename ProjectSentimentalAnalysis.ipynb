{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis Final Project - Tommaso Pessina 961739\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to address the Hate Speech detection problem. We will address two problem: Hate Speech and Sexism.\n",
    "For the sexism text classification method, since the label are dichotomous we will use a simple logistic regression method.\n",
    "For the hate speech classification method, since we have three categorical variable and since we use the Logistic regression method exported by the sklearn.linear_model.LogisticRegression it will recognize that it is not a binary problem and it will address a multiclass problem with a Multinomial Logisitic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need to import the necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing as preproc\n",
    "from sklearn.feature_extraction import text\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import the dataset for the basic hate speech detection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"labeled_data.csv\") \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we should clean the tweet text in order to obtain more clear and understandable sentences that will make the model to perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tompe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text, remove_stopwords = True):\n",
    "    # Remove unwanted characters and stopwords\n",
    "    \n",
    "    delete_list = [\"@user\",\"@url\"]\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'@[a-zA-Z0-9-_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]*', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub('rt', ' ', text)\n",
    "    \n",
    "    for word in delete_list:\n",
    "        if word in text:\n",
    "            text = text.replace(word, \"\")\n",
    "    \n",
    "    # remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "   # text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def clean_text_bigrams(text, remove_stopwords = True):\n",
    "     # Remove unwanted characters and stopwords\n",
    "    delete_list = [\"@user\",\"@url\"]\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'@[a-zA-Z0-9-_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]*', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub('rt', ' ', text)\n",
    "    \n",
    "    for word in delete_list:\n",
    "        if word in text:\n",
    "            text = text.replace(word, \"\")\n",
    "    \n",
    "    # remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "    return list(nltk.bigrams(text))\n",
    "        \n",
    "def cleanLabel(text):\n",
    "    if \"_\" in text:\n",
    "        x = text.split(\"_\")\n",
    "        return x[1]\n",
    "    else:\n",
    "        return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Tweet_Cleaned</th>\n",
       "      <th>Sentiment_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>woman complain cleaning house amp man always t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>boy dats cold tyga dwn bad cuffin dat hoe 1st ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>dawg ever fuck bitch sta cry confused shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>shit hear might true might faker bitch told ya...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                       Tweet_Cleaned  Sentiment_Cleaned  \n",
       "0  woman complain cleaning house amp man always t...                  2  \n",
       "1  boy dats cold tyga dwn bad cuffin dat hoe 1st ...                  1  \n",
       "2         dawg ever fuck bitch sta cry confused shit                  1  \n",
       "3                                   look like tranny                  1  \n",
       "4  shit hear might true might faker bitch told ya...                  1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tweet_Cleaned'] = list(map(clean_text, data.tweet))\n",
    "data['Sentiment_Cleaned'] = data[\"class\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we divide the dataset into train and test using the 70-30 rule, which imply that the 70% of our dataset will be the train set.\n",
    "We choose to fit a Logistc Regression becuase usually with text problem, a simpler model will perform better. In particular we fit a model with Bag Of Word and with TF-IDF method. Moreover, in order to select the best parameter, we run a GridSearch 5-cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = sklearn.model_selection.train_test_split(data, train_size = 0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_transform = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[3,3], lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17348, 9)\n",
      "(7435, 9)\n"
     ]
    }
   ],
   "source": [
    "print(training_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_bow = bow_transform.fit_transform(training_data['Tweet_Cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9339"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_transform.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17348, 9339)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_bow = bow_transform.transform(test_data['Tweet_Cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = training_data['Sentiment_Cleaned']\n",
    "y_te = test_data['Sentiment_Cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transform = text.TfidfTransformer(norm=None)\n",
    "X_tr_tfidf = tfidf_transform.fit_transform(X_tr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_tfidf = tfidf_transform.transform(X_te_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to fit a Logistc Regression becuase usually with text problem, a simpler model will perform better. As said, here the label are not dichotomous, sklearn understand that and it will select a Multinomial Logistic Regression method to address the Multi-class Text Classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
    "    model = LogisticRegression(C=_C).fit(X_tr, y_tr)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Test Score with', description, 'features', score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with bow features 0.8774714189643578\n",
      "Test Score with tf-idf features 0.8360457296570276\n"
     ]
    }
   ],
   "source": [
    "model_bow = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'bow')\n",
    "model_tfidf = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'tf-idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ = {'C': [1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2]}\n",
    "bow_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5, param_grid=param_grid_)\n",
    "tfidf_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5,\n",
    "                                   param_grid=param_grid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0]})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_search.fit(X_tr_bow, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8970488218830763"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0]})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_search.fit(X_tr_tfidf, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8902469380922671"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = open('tfidf_gridcv_results.pkl', 'wb')\n",
    "pickle.dump(bow_search, results_file, -1)\n",
    "pickle.dump(tfidf_search, results_file, -1)\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = open('tfidf_gridcv_results.pkl', 'rb')\n",
    "bow_search = pickle.load(pkl_file)\n",
    "tfidf_search = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bow</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.774902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.830470</td>\n",
       "      <td>0.890247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.897049</td>\n",
       "      <td>0.871628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.883675</td>\n",
       "      <td>0.851107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.864595</td>\n",
       "      <td>0.847014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.854911</td>\n",
       "      <td>0.849435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bow     tfidf\n",
       "0  0.774902  0.774902\n",
       "1  0.830470  0.890247\n",
       "2  0.897049  0.871628\n",
       "3  0.883675  0.851107\n",
       "4  0.864595  0.847014\n",
       "5  0.854911  0.849435"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "search_results = pd.DataFrame.from_dict({'bow': bow_search.cv_results_['mean_test_score'],\n",
    "                               'tfidf': tfidf_search.cv_results_['mean_test_score']})\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = sns.boxplot(data=search_results, width=0.4)\n",
    "ax.set_ylabel('Accuracy', size=14)\n",
    "ax.tick_params(labelsize=14)\n",
    "plt.savefig('tfidf_gridcv_results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit a logist regression model with the best parameter selected by the cross validation runned before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with bow features 0.8887693342299933\n",
      "Test Score with tf-idf features 0.8835238735709482\n"
     ]
    }
   ],
   "source": [
    "model_bow = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'bow', \n",
    "                              _C=bow_search.best_params_['C'])\n",
    "model_tfidf = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'tf-idf', \n",
    "                              _C=tfidf_search.best_params_['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the most relevant feature (i.e. the word that will impact the most on the outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>1.509241</td>\n",
       "      <td>f a g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337</th>\n",
       "      <td>0.789540</td>\n",
       "      <td>f u c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9336</th>\n",
       "      <td>0.675509</td>\n",
       "      <td>n i g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9335</th>\n",
       "      <td>0.628503</td>\n",
       "      <td>h i t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>0.563003</td>\n",
       "      <td>i g g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.324189</td>\n",
       "      <td>r a t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.333453</td>\n",
       "      <td>t o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.411769</td>\n",
       "      <td>i r d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.429031</td>\n",
       "      <td>a m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.509568</td>\n",
       "      <td>b i r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9339 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coefficient   word\n",
       "9338     1.509241  f a g\n",
       "9337     0.789540  f u c\n",
       "9336     0.675509  n i g\n",
       "9335     0.628503  h i t\n",
       "9334     0.563003  i g g\n",
       "...           ...    ...\n",
       "4       -0.324189  r a t\n",
       "3       -0.333453    t o\n",
       "2       -0.411769  i r d\n",
       "1       -0.429031  a m  \n",
       "0       -0.509568  b i r\n",
       "\n",
       "[9339 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = bow_transform.get_feature_names() \n",
    "coefs_with_fns = sorted(zip(model_bow.coef_[0], feature_names)) \n",
    "df=pd.DataFrame(coefs_with_fns)\n",
    "df.columns='coefficient','word'\n",
    "df.sort_values(by='coefficient',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run some test with our two different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = [\"shut the fuck up\",\"you are a faggot dude\",\"hello my friend\",\"i hate you\"]\n",
    "t = bow_transform.transform(te)\n",
    "t1 = tfidf_transform.transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23439021, 0.75001485, 0.01559495],\n",
       "       [0.0839548 , 0.90529618, 0.01074902],\n",
       "       [0.02227623, 0.26035903, 0.71736473],\n",
       "       [0.12022878, 0.36435868, 0.51541254]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model_bow.predict_proba(t)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16128322, 0.78723039, 0.05148639],\n",
       "       [0.17569906, 0.78554549, 0.03875545],\n",
       "       [0.04666329, 0.50440308, 0.44893362],\n",
       "       [0.12281105, 0.55971504, 0.31747391]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model_tfidf.predict_proba(t1)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bow.classes_\n",
    "# 0 - hate speech 1 - offensive language 2 - neither"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that the BagOfWord is the model that perform better in this situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sexist\n",
    "Now we will train a logist regression model for sexist text classification. Since here the label are dichotomous, sklearn will select and train a simple logistic regression method to address our binary text classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a woman, that is good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just dress sexy and you will sign any contract.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are you having period ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop being bitchy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I leave early because of her children instead ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  Label\n",
       "0                          For a woman, that is good      1\n",
       "1    Just dress sexy and you will sign any contract.      1\n",
       "2                            Are you having period ?      1\n",
       "3                                  Stop being bitchy      1\n",
       "4  I leave early because of her children instead ...      1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.ExcelFile(r\"ISEP Sexist Data labeling.xlsx\") \n",
    "\n",
    "data = d.parse(0) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should clean the senteces by procedding as before but now we will train also a bgrams model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentiment_Cleaned</th>\n",
       "      <th>Tweet_Cleaned</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a woman, that is good</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>woman good</td>\n",
       "      <td>[(woman, good)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just dress sexy and you will sign any contract.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dress sexy sign contract</td>\n",
       "      <td>[(dress, sexy), (sexy, sign), (sign, contract)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are you having period ?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>period</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop being bitchy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>stop bitchy</td>\n",
       "      <td>[(stop, bitchy)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I leave early because of her children instead ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>leave early children instead husband</td>\n",
       "      <td>[(leave, early), (early, children), (children,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  Label  \\\n",
       "0                          For a woman, that is good      1   \n",
       "1    Just dress sexy and you will sign any contract.      1   \n",
       "2                            Are you having period ?      1   \n",
       "3                                  Stop being bitchy      1   \n",
       "4  I leave early because of her children instead ...      1   \n",
       "\n",
       "   Sentiment_Cleaned                         Tweet_Cleaned  \\\n",
       "0                  1                            woman good   \n",
       "1                  1              dress sexy sign contract   \n",
       "2                  1                                period   \n",
       "3                  1                           stop bitchy   \n",
       "4                  1  leave early children instead husband   \n",
       "\n",
       "                                             bigrams  \n",
       "0                                    [(woman, good)]  \n",
       "1    [(dress, sexy), (sexy, sign), (sign, contract)]  \n",
       "2                                                 []  \n",
       "3                                   [(stop, bitchy)]  \n",
       "4  [(leave, early), (early, children), (children,...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment_Cleaned'] = data.Label \n",
    "data['Tweet_Cleaned'] = list(map(clean_text, data.Sentences))\n",
    "\n",
    "data[\"bigrams\"] = list(map(clean_text_bigrams, data.Sentences))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset by following the same rules applied before and we will proceed in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataS, test_dataS = sklearn.model_selection.train_test_split(data, train_size = 0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3821"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectS = CountVectorizer(\n",
    "    analyzer=lambda x:x\n",
    ")\n",
    "X_tr_bgramsS = count_vectS.fit_transform(training_dataS[\"bigrams\"])\n",
    "X_te_bgramsS = count_vectS.transform(test_dataS[\"bigrams\"])\n",
    "len(count_vectS.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_transformS = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[3,3], lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(795, 5)\n",
      "(342, 5)\n"
     ]
    }
   ],
   "source": [
    "print(training_dataS.shape)\n",
    "print(test_dataS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_bowS = bow_transformS.fit_transform(training_dataS['Tweet_Cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2769"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_transformS.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795, 2769)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_bowS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_bowS = bow_transformS.transform(test_dataS['Tweet_Cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trS = training_dataS['Sentiment_Cleaned']\n",
    "y_teS = test_dataS['Sentiment_Cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformS = text.TfidfTransformer(norm=None)\n",
    "X_tr_tfidfS = tfidf_transformS.fit_transform(X_tr_bowS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_tfidfS = tfidf_transformS.transform(X_te_bowS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
    "    model = LogisticRegression(C=_C).fit(X_tr, y_tr)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Test Score with', description, 'features', score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with bow features 0.7865497076023392\n",
      "Test Score with tf-idf features 0.7456140350877193\n"
     ]
    }
   ],
   "source": [
    "model_bowS = simple_logistic_classify(X_tr_bowS, y_trS, X_te_bowS, y_teS, 'bow')\n",
    "model_tfidfS = simple_logistic_classify(X_tr_tfidfS, y_trS, X_te_tfidfS, y_teS, 'tf-idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with bow features 0.6578947368421053\n"
     ]
    }
   ],
   "source": [
    "model_bgramS = simple_logistic_classify(X_tr_bgramsS, y_trS, X_te_bgramsS, y_teS, 'bow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gridS_ = {'C': [1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2]}\n",
    "bow_searchS = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5, param_grid=param_gridS_)\n",
    "tfidf_searchS = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5,\n",
    "                                   param_grid=param_gridS_)\n",
    "\n",
    "bgrams_searchS = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5, param_grid=param_gridS_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0]})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgrams_searchS.fit(X_tr_bgramsS, y_trS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6125786163522012"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgrams_searchS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgrams_searchS.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0]})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_searchS.fit(X_tr_bowS, y_trS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012578616352201"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_searchS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_searchS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_searchS.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0]})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_searchS.fit(X_tr_tfidfS, y_trS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_searchS.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779874213836478"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_searchS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_searchS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = open('sexism_gridcv_results.pkl', 'wb')\n",
    "pickle.dump(bow_searchS, results_file, -1)\n",
    "pickle.dump(tfidf_searchS, results_file, -1)\n",
    "results_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = open('sexism_gridcv_results.pkl', 'rb')\n",
    "bow_search = pickle.load(pkl_file)\n",
    "tfidf_search = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5408805 , 0.61886792, 0.80125786, 0.77735849, 0.76603774,\n",
       "       0.75471698])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_searchS.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bow</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>bgrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.540881</td>\n",
       "      <td>0.540881</td>\n",
       "      <td>0.540881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.618868</td>\n",
       "      <td>0.778616</td>\n",
       "      <td>0.540881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.801258</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.563522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.777358</td>\n",
       "      <td>0.761006</td>\n",
       "      <td>0.602516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.766038</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.612579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.730818</td>\n",
       "      <td>0.588679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bow     tfidf    bgrams\n",
       "0  0.540881  0.540881  0.540881\n",
       "1  0.618868  0.778616  0.540881\n",
       "2  0.801258  0.779874  0.563522\n",
       "3  0.777358  0.761006  0.602516\n",
       "4  0.766038  0.742138  0.612579\n",
       "5  0.754717  0.730818  0.588679"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "search_resultsS = pd.DataFrame.from_dict({'bow': bow_searchS.cv_results_['mean_test_score'],\n",
    "                                        'tfidf': tfidf_searchS.cv_results_['mean_test_score'],\n",
    "                                        'bgrams': bgrams_searchS.cv_results_['mean_test_score']})\n",
    "search_resultsS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = sns.boxplot(data=search_resultsS, width=0.4)\n",
    "ax.set_ylabel('Accuracy', size=14)\n",
    "ax.tick_params(labelsize=14)\n",
    "plt.savefig('tfidf_gridcv_results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with bow features 0.8070175438596491\n",
      "Test Score with tf-idf features 0.7660818713450293\n",
      "Test Score with bgrams features 0.6228070175438597\n"
     ]
    }
   ],
   "source": [
    "model_bowS = simple_logistic_classify(X_tr_bowS, y_trS, X_te_bowS, y_teS, 'bow', \n",
    "                              _C=bow_searchS.best_params_['C'])\n",
    "model_tfidfS = simple_logistic_classify(X_tr_tfidfS, y_trS, X_te_tfidfS, y_teS, 'tf-idf', \n",
    "                              _C=tfidf_searchS.best_params_['C'])\n",
    "model_bgramS = simple_logistic_classify(X_tr_bgramsS, y_trS, X_te_bgramsS, y_teS, 'bgrams', \n",
    "                              _C=bgrams_searchS.best_params_['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can analyse the most relevant feature (i.e. the word that will impact the most on the outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>2.226084</td>\n",
       "      <td>(sexist, right)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>2.226084</td>\n",
       "      <td>(sexist, realist)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>2.226084</td>\n",
       "      <td>(blond, want)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>1.999973</td>\n",
       "      <td>(women, cannot)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>1.969758</td>\n",
       "      <td>(believe, women)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.845930</td>\n",
       "      <td>(good, man)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.850283</td>\n",
       "      <td>(opinion, valid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.031441</td>\n",
       "      <td>(one, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.268173</td>\n",
       "      <td>(women, men)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.268713</td>\n",
       "      <td>(impo, ant)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3821 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coefficient               word\n",
       "3820     2.226084    (sexist, right)\n",
       "3819     2.226084  (sexist, realist)\n",
       "3818     2.226084      (blond, want)\n",
       "3817     1.999973    (women, cannot)\n",
       "3816     1.969758   (believe, women)\n",
       "...           ...                ...\n",
       "4       -1.845930        (good, man)\n",
       "3       -1.850283   (opinion, valid)\n",
       "2       -2.031441        (one, said)\n",
       "1       -2.268173       (women, men)\n",
       "0       -2.268713        (impo, ant)\n",
       "\n",
       "[3821 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = count_vectS.get_feature_names() \n",
    "coefs_with_fns = sorted(zip(model_bgramS.coef_[0], feature_names)) \n",
    "df=pd.DataFrame(coefs_with_fns)\n",
    "df.columns='coefficient','word'\n",
    "df.sort_values(by='coefficient',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As good practice here we should check if the dataset is well balanced between different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment_Cleaned\n",
       "0    513\n",
       "1    624\n",
       "Name: Tweet_Cleaned, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = data.groupby(['Sentiment_Cleaned']).count()[\"Tweet_Cleaned\"]\n",
    "num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will prepare our sentences for the sentiment detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = [clean_text(\"women can't think about career\"),clean_text(\"man and women are awesome together\"),clean_text(\"Just dress sexy a bitch and you will get the job\")]\n",
    "tb = [clean_text_bigrams(clean_text(\"women can't think about career\")),clean_text_bigrams(clean_text(\"man and women are awesome together\")),clean_text_bigrams(clean_text(\"Just dress sexy and you will get the job\"))]\n",
    "t = bow_transformS.transform(te)\n",
    "t1 = tfidf_transformS.transform(t)\n",
    "t2 = count_vectS.transform(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model_bowS.predict(t)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model_tfidfS.predict(t1)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = model_bgramS.predict(t2)\n",
    "ynew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bowS.classes_\n",
    "# where \"1\" represents sexism and \"0\" represents no sexism or neutrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above we may say that the bigrams model and the TF-IDF model performs equally well. But form the Test Score we can see that the TF-IDF model will perfom better, so we will chose this one as winner for this job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "Here we propose a typical pipeline for our text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentece1 = \"I love my wife\"\n",
    "sentece2 = \"if you want to work you must dress like a bitch\"\n",
    "sentece3 = \"you are so retarded!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love my wife'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentece1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if you want to work you must dress like a bitch'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentece2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you are so retarded!'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentece3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = [sentece1,sentece2,sentece3]\n",
    "t = bow_transform.transform(te)\n",
    "t1 = tfidf_transform.transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynewBow = model_bow.predict(t)\n",
    "ynewBow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynewTf = model_tfidf.predict(t1)\n",
    "ynewTf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "teS = [clean_text(sentece1),clean_text(sentece2),clean_text(sentece3)]\n",
    "tS = bow_transformS.transform(teS)\n",
    "t1S = tfidf_transformS.transform(tS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynewS = model_tfidfS.predict(t1S)\n",
    "ynewS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dS = dict(zip(te, ynewS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(te, ynewBow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I love my wife': 2,\n",
       " 'if you want to work you must dress like a bitch': 1,\n",
       " 'you are so retarded!': 1}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I love my wife': 0,\n",
       " 'if you want to work you must dress like a bitch': 1,\n",
       " 'you are so retarded!': 0}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I love my wife' is NOT offensive or sexist.\n",
      "'if you want to work you must dress like a bitch' is OFFENSIVE and SEXIST.\n",
      "'you are so retarded!' is OFFENSIVE.\n"
     ]
    }
   ],
   "source": [
    "for key in d:\n",
    "    n = d[key]\n",
    "    if n != 2: #if is offensive\n",
    "        if dS[key] != 0:\n",
    "            print(\"'\"+ key + \"' is OFFENSIVE and SEXIST.\")\n",
    "        else:\n",
    "            print(\"'\"+ key + \"' is OFFENSIVE.\")\n",
    "    else:\n",
    "        print(\"'\"+ key + \"' is NOT offensive or sexist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
